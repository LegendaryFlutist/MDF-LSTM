{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Separate the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c0e054e4512aa1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import dimCols\n",
    "\n",
    "dataDirDev = \".\" + os.sep + \"dataPackage\"\n",
    "featDirDev = \".\" + os.sep + \"data_feats\" + os.sep + \"combined\"\n",
    "modelDirDev = \".\" + os.sep + \"model_eval\"\n",
    "\n",
    "expType = \"task-ils\"\n",
    "dataDir = dataDirDev + os.path.sep + expType\n",
    "featFiles = [f.path for f in os.scandir(featDirDev) if (f.is_file() and not f.name.startswith('.'))]\n",
    "column_names = ['data', 'difficulty', 'flag', 'cumulative_total_error','fd']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "perfMetricsDF = pd.read_csv(dataDirDev + os.path.sep + expType + os.path.sep + \"PerfMetrics.csv\")\n",
    "\n",
    "# 频域特征\n",
    "featDirDev = \".\" + os.sep + \"data_feats\"\n",
    "expType = \"task-ils\"\n",
    "aggFeatFilePath = featDirDev + os.path.sep + 'devSubjsFeatMat.csv'\n",
    "featCols = dimCols.featCols\n",
    "dim_16 = pd.read_csv(aggFeatFilePath)\n",
    "dim_16.columns = [col.strip() for col in dim_16.columns]\n",
    "for col in dim_16.columns:\n",
    "    if pd.api.types.is_string_dtype(dim_16[col]):  # 检查列是否为字符串类型\n",
    "        dim_16[col] = dim_16[col].str.strip()  # 消除字符串前后的空格\n",
    "# Percent of subjects to hold out for validation\n",
    "dim_16[featCols] = zscore(dim_16[featCols])\n",
    "\n",
    "inclDiffLevels = [1,4]\n",
    "for featFile in featFiles:\n",
    "    name_list = featFile.split(\"_\")\n",
    "    level = int(name_list[3].split(\"-\")[1][-2])\n",
    "    sub = int(name_list[1].split(\"\\\\\")[2].split(\"-\")[1][-3:])\n",
    "    date = name_list[2].split(\"-\")[1]\n",
    "    run = int(name_list[3].split(\"-\")[3])\n",
    "    pdf = perfMetricsDF.query(f'subject == {sub} and date == {date} and run == {run}')\n",
    "    subject = name_list[1].split(\"\\\\\")[2]\n",
    "    session = name_list[2]\n",
    "    run_1 = name_list[3]\n",
    "    # 替换 '_run' 为 '-run'\n",
    "    run_1 = run_1.replace('-run', '_run')\n",
    "    fd = dim_16.query(f'Subject == \"{subject}\" and Session == \"{session}\" and Run == \"{run_1}\"')\n",
    "    if level not in inclDiffLevels:\n",
    "        continue\n",
    "    feat = pd.read_csv(featFile)\n",
    "    new_row = {\n",
    "        'data': feat,\n",
    "        'difficulty': level,  # 将 level 添加到 'difficulty' 列\n",
    "        'flag': featFile,  # 将文件名添加到 'flag' 列\n",
    "        'cumulative_total_error': pdf['cumulative_total_error'],\n",
    "        'fd': fd[featCols].values\n",
    "    }\n",
    "    new_index = len(df.index)\n",
    "    df.loc[new_index] = new_row\n",
    "numDirs = len(df)\n",
    "featCols = dimCols.featCols_combin\n",
    "# 假设我们要打印 0 到 99 的数字\n",
    "\n",
    "    # 划分数据集 测试25 训练75\n",
    "pctHoldout = 25\n",
    "numDirs = len(df)\n",
    "numVal = int(numDirs * float(pctHoldout) / 100)\n",
    "numTrain = numDirs - numVal\n",
    "index_array = np.arange(len(df))\n",
    "np.random.shuffle(index_array)\n",
    "df = df.iloc[index_array]\n",
    "trainDF = df[:numTrain]\n",
    "valDF = df[numTrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "training LSTM model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9854dfb7989a3003"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def trainDiffPredictionModel_LSTM(trainDF, valDF, inclDiffLevels, featCols):\n",
    "    # 准备训练数据\n",
    "    x_train_list, train_steps = scaler.get_lstm_data_standard(trainDF, featCols)\n",
    "    y_train = trainDF['difficulty'].values\n",
    "    y_train[y_train == 4] = 0\n",
    "    x_train_ragged = tf.ragged.constant(x_train_list, dtype=np.float32)\n",
    "\n",
    "    # 准备验证数据\n",
    "    x_valid_list, valid_steps = scaler.get_lstm_data_standard(valDF, featCols)\n",
    "    y_valid = valDF['difficulty'].values\n",
    "    y_valid[y_valid == 4] = 0\n",
    "    x_valid_ragged = tf.ragged.constant(x_valid_list, dtype=np.float32)\n",
    "\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    # 设置 LSTM 层的 input_shape 以接受任意长度的序列\n",
    "    model.add(LSTM(128, activation='tanh', return_sequences=False, input_shape=(None, len(featCols))))\n",
    "    # 使用Dropout来减少过拟合\n",
    "    model.add(Dropout(0.5))\n",
    "    # 添加一个Dense层用于最终预测，使用sigmoid激活函数适用于二分类问题\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "    # 编译模型  'categorical_crossentropy'多分类 'binary_crossentropy'\n",
    "    optimizer = Adam(learning_rate=0.0003, clipnorm=1.0)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "    # 训练模型\n",
    "    history = model.fit(x_train_ragged, y_train, epochs=20, batch_size=16, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_data=(x_valid_ragged, y_valid))\n",
    "    plothisAccuracy(history)\n",
    "    # 返回模型\n",
    "    return model\n",
    "\n",
    "def plothisAccuracy(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # 绘制准确度曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e4b0bb4d28bed49"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14fe9fd65deef012"
  },
  {
   "cell_type": "markdown",
   "source": [
    "test and verify"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "752e5d6f7867f675"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def validateDiffPredictionModel_lstm(valMatDF, inclDiffLevels, featCols, clf):\n",
    "    y_actual = valMatDF['difficulty'].values\n",
    "    y_actual[y_actual == 4] = 0\n",
    "    x_list, steps = scaler.get_lstm_data_standard(valMatDF, featCols)\n",
    "\n",
    "    x_ragged = tf.ragged.constant(x_list, dtype=np.float32)\n",
    "    y_p = clf.predict(x_ragged)\n",
    "    print(\"combined2  y_p = \" + str(y_p))\n",
    "    y_p = y_p[:, 0]\n",
    "    optimal_threshold_1 = 0.5\n",
    "    y_pred = np.where(y_p > optimal_threshold_1, 1, 0)\n",
    "    my_plot(\"combined2\", y_pred, y_actual, inclDiffLevels)\n",
    "    roc_auc(y_actual, y_p)\n",
    "    \n",
    "def my_plot(method, y_pred, y_actual, inclDiffLevels):\n",
    "    print(method + \" Actual = \" + str(y_actual))\n",
    "    print(method + \" Predicted = \" + str(y_pred))\n",
    "    # print(method + \" Model's Confidence Probabilities = \" + str(probas))\n",
    "    precision = None\n",
    "    recall = None\n",
    "    f1 = None\n",
    "    if len(inclDiffLevels) > 2:\n",
    "        precision = precision_score(y_actual, y_pred, average='macro')\n",
    "        recall = recall_score(y_actual, y_pred, average='macro')\n",
    "        f1 = f1_score(y_actual, y_pred, average='macro')\n",
    "    else:\n",
    "        precision = precision_score(y_actual, y_pred)\n",
    "        recall = recall_score(y_actual, y_pred)\n",
    "        f1 = f1_score(y_actual, y_pred)\n",
    "\n",
    "    print(method + f\" 精确值: {precision:.4f}\")  # 添加小数点后四位的格式化\n",
    "    print(method + f\" 召回率: {recall:.4f}\")\n",
    "    print(method + f\" F1分数: {f1:.4f}\")\n",
    "\n",
    "\n",
    "def roc_auc(y_actual, y_p):\n",
    "    fpr, tpr, thresholds = roc_curve(y_actual, y_p)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # 绘制ROC曲线\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(fpr, tpr, lw=2)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multimodal Data Fusion LSTM \\n ROC Curve for Validation Set. AUC = ' + str(roc_auc))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8926855c2b5e7a97"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
